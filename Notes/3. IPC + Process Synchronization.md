# Inter Process Communication (IPC)
Sharing communication from one process to another process.
- sometimes you need to control the flow of another process, from a different process

Processes within a system may be **independent or cooperating** 
- An **independent** process cannot affect or be affected by the execution of the other processes 
- A **cooperating** process can affect or be affected by the other processes, including sharing data
	- **Reasons** for cooperating processes:
		- Information sharing 
		- Computation speedup 
		- Modularity
		- Convenience 
	- Cooperating processes need interprocess communication (IPC)
	- We need cooperating processes in our system.

Three models of IPC:
1. Pipe
	- **Advantages**
		- simple, don't have to interface with the OS (less overhead) with anonymous pipe
		- best if you need a raw data stream
		- less work to use the pipe - don't need to do other system level synchronization
	- **Disadvantages**
		- It's blocking - if you want to read from pipe, consumer process is blocked until reading is done
		- less features - no priority, no message length
		- unidirectional - one-way communication
2. Message Queue
	- **Advantages**
		- both parties have understanding of message structure
			- data stream is more structured
		- programmers can configure the message structure
		- can set message priority - older messages don't HAVE to be read first (unlike pipe)
		- bi-directional (pipe is unidirectional)
	- **Disadvantages**
		- has more features - more overhead
			- don't use it if you don't need to
3. Shared Memory
	- **Advantages**
		- has a higher capacity than both pipe and message queue (can access large amounts of data at once)
			- having multiple pipes isn't a good idea because you will have to manage them all
		- works at speed of memory.
	- **Disadvantages**
		- when you need shared memory, no alternatives
			- there are deadlocks and race conditions - you have to resolve race conditions without creating deadlocks
		- harder to set up -> deadlocks and race conditions

# Pipe
Pipe acts as a conduit allowing two processes to communicate 
Two types:
- **Ordinary pipes** – cannot be accessed from outside the process that created it. Typically, a **parent** process creates a pipe and uses it to communicate with a **child** process that it created. 
	- Limited to two processes (parent and child required)
	- We used this in assignment 1.
	- Ordinary Pipes allow communication in standard **producer-consumer** style
		- **Producer** writes to one end (the write-end of the pipe) 
		- **Consumer** reads from the other end (the read-end of the pipe)
	- Ordinary pipes are therefore **unidirectional**
	- Windows calls these **anonymous pipes**
- **Named pipes** – can be accessed without a parent-child relationship.
	- Named pipes are more powerful than ordinary pipes 
	- No parent-child relationship is necessary between the communicating processes 
	- Several processes can use the named pipe for communication 
	- Communication is **unidirectional** in most of the systems 
	- Provided on both UNIX and Windows systems

Pipe has a default buffer limit defined by OS. This is the max amount of bytes that can be communicated through pipe at once.
- Can't write to the pipe if buffer is full
	- Will instead wait for pipe to read from buffer to free up space. Meaning `read()` is the 'blocking call'

# Message Queue
Also passes info from one process to another process.
- Difference from pipe is that pipe has a constant stream of messages with a max size of buffer, don't have a way of separate messages.
- Message queue has distinct messages that are sent, with a size for each message.
	- If you don't need semantics of **different permissions for different messages**, etc. just use pipe as it is much simpler

Message queues are identified by a given name.

**Message queue** has **configurable** internal structure
- **size** of each message
- **size** of the queue
Provides two operations to the communicating processes
- `send(message)` - put message into queue
- `receive(message)` - get message from queue
**More than two** processes can **send** and **receive**
- **Send** operation assigns a **priority** to each message
	- **Oldest message** with the **highest priority** goes to the **front** of the queue
- **Receive** operation gets and removes the front message from the queue.

A process can check the **status** of the queue

# Shared Memory
Shared memory is an **area** of **memory shared** among the processes that wish to communicate.

- The communication is under the **control** of the **user's processes**, not the operating system. 
- The major issue is to provide a mechanism that will allow the user processes to **synchronize their actions** when they access shared memory to avoid the **race condition.**

## Race Condition
- The race condition is **data inconsistency** in shared memory caused by simultaneous access by two or more processes.
	- One process writes to memory but another process overwrites that memory as well.
- The **critical region** is the **code segment** that causes the race condition (i.e. the code that accesses the shared memory)

### Requirements to avoid race conditions:
Video: https://www.youtube.com/watch?v=UtEORPakw5Y
- **Mutual Exclusion:** No two processes may be simultaneously inside their **critical regions.**
- No assumptions may be made about the **number of CPUs or their speeds.**
- **Progress:** A process running **outside** its **critical region** must **not block** other processes. 
	- Selection of what process can enter critical region cannot be postponed indefinitely.
- **Bounded-Waiting:** A process must not have to **wait forever** to enter its **critical region**

## Critical Region Mutual Exclusion
A **critical section/region** is a segment of code in a process where the process may be changing common variables, updating a table, etc. in shared memory.
![[critregionexclusion.png]]
- How do we code this?

The **critical region problem** is designing a protocol that the processes can use to cooperate, fulfilling the "avoiding the race condition" requirements.
- **Mutual Exclusion:** No two processes may be simultaneously inside their **critical regions.**
- **Progress:** A process running **outside** its **critical region** must **not block** other processes. 
- **Bounded-Waiting:** A process must not have to **wait forever** to enter its **critical region**

Can think of the process as having sections:
- The **entry section** is the section of code implements a request for permission to enter its **critical section**.
- The **critical section** itself, where shared memory is accessed.
- The **exit section**, where the process leaves the critical section.
- The **remainder section**, which is all remaining code.

## Mutual Exclusion with Busy Waiting
#### Strict Alternation
```c
// Mutual Exclusion with Busy Waiting - Strict Alternation

// Process 0
	
	while (TRUE) {
		while (turn != 0); // loop
		critical_region();
		turn = 1;
		noncritical_region)(;)
	}

// Process 1
	
	while (TRUE) {
		while (turn != 1); // loop
		critical_region();
		turn = 0;
		noncritical_region();
	}

```
- This is a proposed solution to the critical region problem.
	- Doesn't work because there is a case where a process running outside its critical region is blocking other processes from entering the critical region.

#### Peterson's Solution 
Video: https://www.youtube.com/watch?v=gYCiTtgGR5Q
```c
// Mutual Execlusion with Busy Waiting - Peterson's Solution

	#define FALSE 0
	#define TRUE 1
	#define N 2
	// Shared among both processes:
	int turn = 0;
	int interested[N] = {FALSE, FALSE};
	
	void enter_region(int process) {
		int other = 1 – process;
		interested[process] = TRUE;
		turn = process;
		while (turn == process && interested[other] == TRUE); //busy wait
	}
	
	void leave_region(int process) {
		interested[process] = FALSE;
	}

	int process = 0;
	while(TRUE) {
		enter_region(0); //busy wait process 0
		critical_region();
		leave_region(0);
		noncritical_region();
	}

	int process = 1;
	while(TRUE) {
		enter_region(1); //busy wait process 1
		critical_region();
		leave_region(1);
		noncritical_region();
	}

```
- Turn variable and interested flags are shared among processes.
	- If two processes enter `enter_region()` at the same time, whatever process was slower to the line `turn = process` will overwrite the turn variable and have its turn.
- Good for satisfying **bounded-waiting** condition
- Test question on this

Can't implement it with a lock variable since the lock variable itself suffers from the race condition.
- Only works if we have **only two processes** accessing the same shared memory.

#### The Test and Set Lock (TSL) Instruction 
Video: https://www.youtube.com/watch?v=5oZYS5dTrmk
This is a **hardware** solution to the critical-region problem.
- **Shared lock variable** which can be either 0 or 1.
- Before entering critical section, process inquires about the lock
	- If it is locked (lock is 1), keep on waiting until it becomes free
	- If it is unlocked (lock is 0), takes the lock (sets to 1) and executes critical section
	- `TSL` instruction checks the current value of the lock and then changes the **shared lock variable to 1**
		- It is an **atomic operation** (can't be interrupted)
		- ![[tsl_instruction.png]]
	- If lock value that was copied into register is not 0, loops back to TSL instruction again
![[tslinstruction.png]]
- Entering and leaving a critical region using the TSL instruction.
- Does not satisfy **bounded-waiting**.

#### The XCHG Instruction:
![[xchginstructionexclusion.png]]
- Entering and leaving a critical region using the XCHG instruction.
- Functionally the same thing as the TSL instruction

# Producer-Consumer Problem 
 Scenario: one or more "producer" processes create data and place it into a shared, fixed-size buffer, while one or more "consumer" processes retrieve and process the data from the buffer. 
- Buffer can get full and producers must wait until consumers remove an item before it can add a new one
- Buffer can be empty and a consumer must wait until a producer adds an item
- Only one process (either a producer or consumer) should be able to access the buffer at a time (to prevent race condition)
## Sleep and Wakeup
**Producer**
```c
	// Producer code in producer-consumer problem using sleep and wakeup.
	
	#define N 100; //number of slots in the buffer
	int count = 0; //number of items in the buffer
		
	void producer(void){
		int item;
		
		while(TRUE) { //repeat forever
			item = produce_item(); //generate next item
			if (count == N) sleep; //if buffer is full, go to sleep
			insert_item(item); //put item in buffer
			count = count + 1; //increment count of items in buffer
			if (count == 1) wakeup(consumer); //was buffer empty?
		}
	}
```

**Consumer**
```c
	// Consumer code in producer-consumer problem using sleep and wakeup.

	void consumer(void){
		int item;
		
		while(TRUE) { //repeat forever
			if (count == 0) sleep(); //if the buffer is empty, go to sleep
			item = remove_item(); //take item out of buffer
			count = count - 1; //decrement count of items in buffer
			if (count == N - 1) wakeup(producer); //was buffer full?
			consume_item(item); //print item
		}
	}
```
##### Problems
- **Race condition:** 
	- `count` is shared between producers and consumers, but not mutually excluded. 
	- `insert_item()` is a critical region among producers and it is not mutually excluded
	- `remove_item()` is a critical region among consumers and it is not mutually excluded
- **Deadlock:** 
	- `wakeup` signal from producer gets lost if consumer is rescheduled before it executes the `sleep()` function.
	- `wakeup` signal from consumer gets lost if producer is rescheduled before it executes the `sleep()` function.

## Semaphores
A **semaphore** is a synchronization tool used to control access to shared resources.
- A semaphore is **initialized** to a specific integer value representing the number of available resources
- When a process wants to **access the shared resource**, it performs a `wait` operation.
	- If the semaphore's value is greater than zero, the value is decremented.
	- If the semaphore's value is zero, the process is **blocked** and must wait until the resource becomes available (non-zero)
```c
	void wait(Semaphore S) {
		while (S <= 0); // wait
		S--;
	}
```

- When a process is **done with the shared resource**, it will perform a `signal` operation.
	- This increments the semaphore's value, indicating there is one more resource available.
```c
	void signal(Semaphore S) {
		S++;
	}
```

When one process modifies the semaphore value, no other process can simultaneously modify that same semaphore value.

#### Semaphore Disadvantages
Semaphores and other busy waiting algorithms/solutions suffer from wasting CPU cycles being stuck in while loop, this is a big waste of resources.
- Semaphore with a waiting queue (process blocking itself) may solve this, but then can cause deadlocks and starvation

### Semaphore Solution
**Producer**
```c
	// Producer code in producer-consumer problem using semaphores.
	
	#define N 100 //number of slots in the buffer
	typedef int semaphore; //special kind of int (already present in c)
	semaphore mutex = 1; //controls access to critical region
	semaphore empty = N; //counts empty buffer slots
	semaphore full = 0; //counts full buffer slots
	
	void producer(void){
		int item;
		
		while(TRUE){ //always runs
			item = produce_item(); //generate something for the buffer
			wait(&empty); // decrement empty count
			wait(&mutex); // enter the critical region
			insert_item(item); //put new item in the buffer
			signal(&mutex); //leave critical region
			signal(&full); //increment count of full slots
		}
	}
```
- **No race condition**: no shared `count` with the consumer. The `insert_item()` critical region is mutually excluded by the **semaphore mutex.**
#### Problem
- **Deadlock**: `signal` signal from consumer on the **semaphore empty** is held if the producer is rescheduled before it executes `wait(&empty)` function.

**Consumer**
```c	

	// Consumer code in producer-consumer problem using semaphores.

	void consumer (void){
		int item;
		
		while(TRUE){ //infinite loop
			wait(&full); //decrement full count
			wait(&mutex); //enter critical region
			item = remove_item(); //take item from buffer
			signal(&mutex); //leave critical region
			signal(&empty); //increment count of empty slots
			consume_item(item); //do something with the item;
		}
	}

```
- **No Race condition**: no shared `count` with producer. The `remove_item()` critical region is mutually excluded by **semaphore mutex.** 
#### Problem
- **Deadlock**: `signal` signal from producer on **semaphore full** is held if consumer is rescheduled before it executes `wait(&full)` function.

## Message Queue Solution
**Producer**
![[Pasted image 20251001133213.png]]

**Consumer**
![[Pasted image 20251001133229.png]]

- Waiting and signalling is done by `send()` and `receive()`
- Consumer sends an "echo" or empty message to signal to producer it has received the item.

## Mutexes
(Like a binary semaphore - a semaphore that can only be 0 or 1)
### Mutexes as a TSL instruction in assembly:
- TSL stands for "test and set lock"

Implementation of `mutex_lock` and `mutex_unlock`
```assembly
	mutex_lock:
		TSL REGISTER, MUTEX // copy mutex to register and set mutex to 1
		CMP REGISTER, #0 // was mutex zero?
		JZE ok // if it was zero, mutex was unlocked, so return
		CALL thread_yield // mutex is busy; schedule another thread
		JMP mutex_lock // try again
	ok: RET // return to caller; critical region entered
	
	mutex_unlock:
		MOVE MUTEX, #0 // store a 0 in mutex
		RET // return to caller
```
- **Spinlock** - stuck in while loop waiting for availability (spinning in lock) and it takes up CPU bursts
	- What process can do is put the thread needing the lock in waiting queue instead of ready queue for CPU scheduling, and give the turn to another thread
		- `CALL thread_yield` lets another thread take CPU time. When the original thread is scheduled again, it tries the lock again.

### Mutexes in Pthread

| Function                  | Description                                                   |
| ------------------------- | ------------------------------------------------------------- |
| `pthread_mutex_init()`    | Create a mutex                                                |
| `pthread_mutex_destroy()` | Destroy an existing mutex                                     |
| `pthread_mutex_lock()`    | Acquire lock on a mutex or block yourself until succeed       |
| `pthread_mutex_trylock()` | Acquire a lock on a mutex or return immediately with an error |
| `pthread_mutex_unlock()`  | Release a lock from a mutex                                   |

### Conditions in Pthread
| Function                   | Description                                                     |
| -------------------------- | --------------------------------------------------------------- |
| `pthread_cond_init()`      | Create a condition variable                                     |
| `pthread_cond_destroy()`   | Destroy an existing condition variable                          |
| `pthread_cond_wait()`      | Wait until a wake up signal is received                         |
| `pthread_cond_signal()`    | Signal a waiting thread to wake it up                           |
| `pthread_cond_broadcast()` | Broadcast a signal to multiple waiting threads and wake them up |

### Producer-Consumer Problem with Pthread Mutexes and Conditions
**Producer**
![[pthreadproducer.png]]
- `condp` used by producer to wait and consumer to signal
- `condc` used by consumer to wait and producer to signal

**Consumer**
![[pthreadconsuer.png]]

**Main routine:**
![[Pasted image 20251001132833.png]]

## Note
**Overall, for producer-consumer problem and when developing applications that require some sort of process synchronization, you have a lot of choices. Different things are simpler and better for different situations and it is your job to make it work.**

# The Dining Philosophers Problem
Multiple "philosophers" are seated around a circular table, with a plate of food in front of each and a single fork (resource) between each pair of plates.
- Each philosopher alternates between **thinking and eating.**
- To eat, a philosopher needs to pick up both the fork to their left and the fork to their right.
	- Literally why?? Just teach them how to eat properly

**Problem:** If every philosopher decides to eat at once, each one will pick up the fork to their left, but needs one to their right, which is already taken, so they can't eat!
- This is a **deadlock** situation, as they are all waiting for a resource that is held by someone else in the group.

Other problem: Could lead to **starvation** of one philosopher, if they can't eat because heir neighbours keep eating (fatties).

## Solution
![[din_philo_sol1.png]]

![[din_philo_sol2.png]]

![[din_philo_sol3.png]]

# The Readers and Writers Problem
The readers and writers problem is a concurrency problem where multiple processes/threads access a shared resource.
- Readers: Multiple readers can access the shared resource at the same time because reading does not alter the data
- Writers: Only **one** writer can access the resource at a time
	- When a writer is accessing the resource, no other reader or writer can access it.

**Problem:**
- **Starvation (Violation of Bounded-Waiting)**: 
	- A continuous stream of readers can **starve writers**, preventing them from ever getting a chance to access the resource.
	- If writers are given higher priority, they can **starve readers** by constantly updating the resource.

## Solution
![[reader_writer_sol1.png]]

![[reader_writer_sol2.png]]